{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "from IPython.display import display\n",
    "from itertools import permutations\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister\n",
    "from qiskit.visualization import plot_histogram\n",
    "from qiskit import Aer, execute\n",
    "from qiskit.circuit import Parameter\n",
    "import networkx as nx\n",
    "\n",
    "from scipy.optimize import minimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### HELPER FUNCTION ####\n",
    "def string_to_arr(string):\n",
    "    arr = []\n",
    "    for str in string: arr.append(int(str))\n",
    "    return np.array(arr).reshape((len(np.array(arr)),1))\n",
    "\n",
    "def score(n1,n2):\n",
    "    \"\"\" Function for computing the score of\n",
    "        some alignment of the two chars n1, n2\n",
    "    Args:\n",
    "        n1: any str in {\"_\",\"A\",\"T\",\"C\",\"G\"}\n",
    "        n2: any str in {\"_\",\"A\",\"T\",\"C\",\"G\"}\n",
    "    Returns:\n",
    "        score: int in {-1,0,1}\n",
    "    \"\"\"\n",
    "    score = None\n",
    "    gap = \"_\"\n",
    "    if   n1 == gap or n2 == gap: score =  0; return score\n",
    "    elif n1 == n2              : score = -1; return score\n",
    "    elif n1 != n2              : score =  1; return score\n",
    "\n",
    "def score_sequence(arr):\n",
    "    \"\"\"Function for computing sum-of-pairs score\n",
    "       according to scheme defined in \n",
    "       score function. \n",
    "    Args:\n",
    "        arr: numpy array, e.g.: np.array([\"A\",\"C\",\"_\",\"T\",\"_\"])\n",
    "    Returns:\n",
    "        final_score: integer \n",
    "       \"\"\"\n",
    "    final_score = 0\n",
    "    for n1 in range(0 , len(arr)):\n",
    "        for n2 in range(n1 + 1 , len(arr)):\n",
    "            final_score += score(arr[n1],arr[n2])\n",
    "    return final_score\n",
    "\n",
    "def recursive_perm_scoring(mat, perms, test_mat, row_idx):\n",
    "    \"\"\"Computing all possibles alignment scores of MSA matrix; mat,\n",
    "       given the permutations for each of the N-1 rows of mat, (found in perms)\n",
    "    \n",
    "    Args:\n",
    "        mat     : 2D numpy array, e.g. array([['A', 'C', 'C', 'T'],\n",
    "                                              ['A', 'C', '_', '_'],\n",
    "                                              ['A', 'T', '_', '_']])\n",
    "        perms   : all distinct permutations of the N-1 last rows of mat\n",
    "        test_mat: matrix \n",
    "       \"\"\"\n",
    "    perm_history, score_history = [], []\n",
    "    if row_idx < mat.shape[0]:\n",
    "        for i in range(0 , len(perms[row_idx - 1])):\n",
    "            test_mat[row_idx,:] = perms[row_idx - 1][i]\n",
    "            score_list, perm_list = recursive_perm_scoring(mat, perms, test_mat, row_idx + 1)\n",
    "            perm_history += perm_list\n",
    "            score_history += score_list\n",
    "            current_score = 0\n",
    "            for j in range(0 , mat.shape[1]):\n",
    "                current_score += score_sequence(test_mat[:,j])\n",
    "            score_history.append(current_score)\n",
    "            perm_history.append(deepcopy(test_mat))\n",
    "    return score_history, perm_history\n",
    "\n",
    "\n",
    "def matrix_2_bit_state(my_matrix,original_matrix):\n",
    "    \"\"\"\n",
    "    Maps some given matrix repr. of a MSA \"my_matrix\" to a corresponding\n",
    "    bitstring via the column encoding, whilst respecting\n",
    "    original order in \"original_matrix\"\n",
    "    x_(s,n,i) determines whether the n'th letter of the s'th string\n",
    "    is placed in the i'th column.\n",
    "\n",
    "    Args:\n",
    "        mat: 2D numpy array, e.g. array([['A', 'C', 'C', 'T'],\n",
    "                                         ['A', 'C', '_', '_'],\n",
    "                                         ['A', 'T', '_', '_']])\n",
    "    Returns:\n",
    "        numpy array containing bit repr., e.g.: np.array([1,0,0,1...])\n",
    "\n",
    "    \"\"\"\n",
    "    ## Initial definitions\n",
    "    current_matrix = deepcopy(my_matrix)\n",
    "    nr_of_rows, nr_of_cols, gap = current_matrix.shape[0], current_matrix.shape[1], \"_\"\n",
    "    ## List of nr of letters in i'th row of original matrix\n",
    "    nr_letters_in_mat = [len(np.where(original_matrix[i] != \"_\")[0]) for i in range(nr_of_rows)]\n",
    "    ## Needed nr of registers\n",
    "    regs = np.array([list(np.zeros(nr_of_cols)) for i in range(np.sum(nr_letters_in_mat))])\n",
    "    ## List of lists of letters in original matrix rows\n",
    "    original_letters = np.array([list(original_matrix[i][np.where(original_matrix[i] != gap)[0]]) \n",
    "                                 for i in range(nr_of_rows)], dtype=object)\n",
    "    #print(regs)\n",
    "    ## List of lists of letters in current matrix rows\n",
    "    current_letters = np.array([list(current_matrix[i][np.where(current_matrix[i] != gap)[0]]) \n",
    "                                for i in range(nr_of_rows)], dtype=object)\n",
    "\n",
    "    for s in range(0 , nr_of_rows):\n",
    "        for n in range(0 , len(current_letters[s])):\n",
    "            ## Finding index\n",
    "            #print(\"current s:\",s)\n",
    "            #print(\"Setting:\",current_letters[s][n])\n",
    "            #print(\"where term:\",np.where(np.array(original_letters[s]) == current_letters[s][n])[0][0])\n",
    "            #print(\"sum term:\",s * int(np.sum(nr_letters_in_mat[:s])))\n",
    "            reg_idx = np.where(np.array(original_letters[s]) == current_letters[s][n])[0][0] + int(np.sum(nr_letters_in_mat[:s])) # Original n'th idx\n",
    "            #print(\"reg. idx.:\",reg_idx)\n",
    "            col_idx = np.where(np.array(current_matrix[s])   == current_letters[s][n])[0][0]                                      # Current i'th idx\n",
    "            #print(\"col. idx.:\", col_idx)\n",
    "            ## Setting reg value\n",
    "            regs[reg_idx][col_idx] = 1\n",
    "            ## Changing comparator to \"O\" (the letter) in case of multiple of same char\n",
    "            original_letters[s][np.where(np.array(original_letters[s]) == current_letters[s][n])[0][0]] = \"O\"\n",
    "            current_matrix[s][ np.where(np.array(current_matrix[s])  == current_letters[s][n])[0][0]] = \"O\"\n",
    "            #print(original_letters,current_letters)\n",
    "            #print(\"_________________\")\n",
    "    return regs.flatten()\n",
    "\n",
    "\n",
    "def bit_state_2_matrix(bit_string,init_mat):\n",
    "    \"\"\"\n",
    "    Maps some given bitstring repr. of a MSA to a corresponding\n",
    "    matrix via the initial matrix. \n",
    "\n",
    "    Args:\n",
    "        bit_string: numpy array containing bit repr., e.g.: np.array([1,0,0,1...])\n",
    "        mat       : 2D numpy array, e.g. array([['A', 'C', 'C', 'T'],\n",
    "                                                ['A', 'C', '_', '_'],\n",
    "                                                ['A', 'T', '_', '_']])\n",
    "    Returns:\n",
    "        2D numpy array, e.g. array([['A', 'C', 'C', 'T'],\n",
    "                                    ['A', 'C', '_', '_'],\n",
    "                                    ['A', 'T', '_', '_']])\n",
    "    \"\"\"\n",
    "    letters_in_mat = [init_mat[i][j] for i in range(init_mat.shape[0]) \n",
    "                      for j in range(init_mat.shape[1]) if init_mat[i][j] != \"_\"]\n",
    "    assert np.sum(bit_string) == len(letters_in_mat), \"Invalid state - to few ones in bitstring\"\n",
    "\n",
    "    counts, letters, gap = [], [], \"_\"\n",
    "    for row in range(init_mat.shape[0]):\n",
    "        current_count = 0\n",
    "        current_letters  = []\n",
    "        for col in range(init_mat.shape[1]):\n",
    "            if init_mat[row][col] != gap: \n",
    "                current_count += 1\n",
    "                current_letters.append(init_mat[row][col])\n",
    "        letters.append(current_letters)\n",
    "        counts.append(current_count)\n",
    "\n",
    "    lower = 0\n",
    "    multiplier, regs = init_mat.shape[1], []\n",
    "    for value in counts:\n",
    "        for i in range(value):\n",
    "            regs.append(bit_string[lower + i * multiplier : lower + (i + 1) * multiplier])\n",
    "        lower += value * multiplier\n",
    "\n",
    "    counter = 0\n",
    "    new_mat = np.zeros((init_mat.shape),dtype=object)\n",
    "    counter = 0\n",
    "    for i in range(len(letters)):\n",
    "        for j in range(len(letters[i])):\n",
    "            col_idx = np.where(regs[counter] == 1)[0][0]\n",
    "            new_mat[i][col_idx] = letters[i][j]\n",
    "            counter += 1\n",
    "\n",
    "    new_mat[new_mat == 0] = \"_\"\n",
    "    return new_mat\n",
    "\n",
    "\n",
    "def legal_permutations(arr): \n",
    "    \"\"\" Function for computing all permutations of array\n",
    "    of type [\"A\",\"C\",\"_\",\"T\",\"_\"] that maintains original\n",
    "    order of characters != \"_\" .\n",
    "\n",
    "    Args:\n",
    "        arr: numpy array, e.g.: np.array([\"A\",\"C\",\"_\",\"T\",\"_\"])\n",
    "    Returns:\n",
    "        2D numpy array of legal permutations, e.g.: np.array([[\"A\",\"C\",\"_\",\"T\",\"_\"],\n",
    "                                                              [\"A\",\"C\",\"_\",\"_\",\"T\"],...])\n",
    "\n",
    "    \"\"\"\n",
    "    legal_perm_indices = []\n",
    "    letter_order = [char for char in arr if char != \"_\"]\n",
    "    perms = list(set(permutations(arr))) # Using set to remove dubs\n",
    "    perms = [list(perm) for perm in perms]\n",
    "    for idx, perm in enumerate(perms):\n",
    "        letter_counter = 0\n",
    "        keep_perm = True\n",
    "        for letter in perm:\n",
    "            if letter != \"_\":\n",
    "                if letter_order[letter_counter] != letter:\n",
    "                    keep_perm = False\n",
    "                else: letter_counter += 1\n",
    "        if keep_perm: legal_perm_indices.append(idx)\n",
    "    return np.array(perms)[legal_perm_indices]\n",
    "\n",
    "def recursive_brute_force(init_mat):\n",
    "    \"\"\" Final recursive version of brute force scoring of all relevant\n",
    "    permutations of variable sized MSA matrix. \n",
    "    (Make sure the longest row containin only letters are\n",
    "     initially placed at top of matrix)\n",
    "     \n",
    "    Args:\n",
    "        Init_mat: 2D numpy array, e.g. array([['A', 'C', 'C', 'T'],\n",
    "                                              ['A', 'C', '_', '_'],\n",
    "                                              ['A', 'T', '_', '_']])\n",
    "    Returns:\n",
    "        best_score: Integer\n",
    "        best perms: list of corresponding permutations of MSA matrix\n",
    "    \"\"\"\n",
    "    perms = []\n",
    "    for row_idx in range(1 , init_mat.shape[0]):\n",
    "        perms.append(legal_permutations(init_mat[row_idx,:]))\n",
    "    test_mat = np.zeros((init_mat.shape) , dtype=object)\n",
    "    test_mat[0,:] = init_mat[0,:]\n",
    "    score_history, mat_history = recursive_perm_scoring(init_mat,perms,test_mat,1)\n",
    "    best_score = np.min(score_history)\n",
    "    best_perms = [mat_history[i] for i in range(len(mat_history)) if score_history[i] == best_score]\n",
    "    return best_score, best_perms\n",
    "\n",
    "\n",
    "def score_matrix(mat: np.ndarray) -> int:\n",
    "    \"\"\"Function for calculating the alignment score\n",
    "    of a MSA matrix\"\"\"\n",
    "    final_score = 0\n",
    "    for col in range(0 , mat.shape[1]):\n",
    "        final_score += score_sequence(mat[:,col])\n",
    "    return final_score\n",
    "\n",
    "def initial_MSA_matrix(init_strings):\n",
    "    \"\"\" Creating a matrix representation of the strings given\n",
    "    and filling gaps with \"_\"\n",
    "\n",
    "    Args:\n",
    "        list of strings, e.g. [\"ACCT\",\"AC\",\"AT\"]\n",
    "\n",
    "    Returns:\n",
    "        2D numpy array\n",
    "    \"\"\"\n",
    "    ## Asurring longest string on top\n",
    "    lengths = np.array([len(str) for str in init_strings])\n",
    "    strings = init_strings[np.flip(np.argsort(lengths, kind=\"heap\"))]\n",
    "    initial_matrix = np.zeros((len(strings) , np.max(lengths)),dtype=object)\n",
    "    for row in range(initial_matrix.shape[0]):\n",
    "        for col in range(len(strings[row])):\n",
    "            initial_matrix[row][col] = strings[row][col]\n",
    "    initial_matrix[initial_matrix == 0] = \"_\"\n",
    "    return initial_matrix\n",
    "    \n",
    "## Function for indexing states\n",
    "def index_state(M,n,s,i,Ns_vals):\n",
    "    \"\"\"Indexing n,s,i from 1,... and adding N_0 = 0 to start og N_s vals\"\"\"\n",
    "    return M * ((n-1) + np.sum(Ns_vals[:s])) + i - 1\n",
    "\n",
    "## Function for indexing given weight term in array\n",
    "def index_weight(s1,n1,s2,n2,i,M, nr_letters):\n",
    "    #w_mat_row_idx = (n1 - 1) + (s1-1) * M + (nr_letters[s2] - 1) * M\n",
    "    w_mat_row_idx = (n1 - 1) + (s2-2) * M + (s1-1) * M\n",
    "    w_mat_col_idx = n2 - 1\n",
    "    return w_mat_row_idx, w_mat_col_idx\n",
    "\n",
    "\n",
    "\n",
    "def encode_score_weights(mat):\n",
    "    \"\"\"Encoding the score of all possible alignments\n",
    "        for all n1, n2 for all s1 < s2 score(n1,n2)\n",
    "\n",
    "    Args:\n",
    "        mat: 2D numpy array, e.g. array([['A', 'C', 'C', 'T'],\n",
    "                                         ['A', 'C', '_', '_'],\n",
    "                                         ['A', 'T', '_', '_']])   \n",
    "    Returns:\n",
    "        weight_matrices: 3D numpy array of shape (1/2 * (L - 1) * L , C , C)\n",
    "                         where L = nr. of rows and C = nr. of cols in\n",
    "                         matrix given\n",
    "    \"\"\"\n",
    "    L, C = mat.shape\n",
    "    weight_matrices = [np.zeros((C,C)) for i in range(int(1/2 * (L - 1) * L))]\n",
    "    for row1 in range(0 , mat.shape[0]):\n",
    "        for row2 in range(row1 + 1 , mat.shape[0]):\n",
    "            for idx1, n1 in enumerate(mat[row1,:]):\n",
    "                for idx2, n2 in enumerate(mat[row2,:]):\n",
    "                    weight_matrices[row1+row2-1][idx1][idx2] = score(n1,n2)\n",
    "    return np.vstack(np.array(weight_matrices))\n",
    "\n",
    "def encode_QUBO(Weights: np.ndarray, MSA: np.ndarray, penalties: np.ndarray):\n",
    "\n",
    "    nr_rows,nr_cols = MSA.shape[0], MSA.shape[1]\n",
    "    nr_letters = [0] + [len(np.where(MSA[i] != \"_\")[0]) for i in range(nr_rows)]\n",
    "    vector_dim = np.sum(nr_letters) * nr_cols\n",
    "\n",
    "    p1,p2,p3   = penalties[0], penalties[1], penalties[2]\n",
    "\n",
    "    Q = p1 * np.identity(vector_dim)\n",
    "    h = -2 * p1 *np.ones(vector_dim).reshape((vector_dim,1))\n",
    "    d = p1 * np.sum(nr_letters)\n",
    "        \n",
    "    ## Weight terms\n",
    "    for s1 in range(1 , nr_rows + 1):\n",
    "        for s2 in range(s1 + 1, nr_rows + 1):\n",
    "            for n1 in range(1 , nr_letters[s1]+ 1):\n",
    "                for n2 in range(1 , nr_letters[s2] + 1):\n",
    "                    for i in range(1 , nr_cols + 1):\n",
    "                        xsni1_idx=index_state(nr_cols,n1,s1,i,nr_letters)\n",
    "                        xsni2_idx=index_state(nr_cols,n2,s2,i,nr_letters)\n",
    "                        row,col = index_weight(s1,n1,s2,n2,i,nr_cols,nr_letters)\n",
    "                        Q[xsni1_idx][xsni2_idx] = Weights[row][col]\n",
    "\n",
    "    ## Remaing part of squared terms in one col pr. letter\n",
    "    for s in range(1 , nr_rows + 1):\n",
    "        for n in range(1 , nr_letters[s] + 1):\n",
    "            for i in range(1 , nr_cols + 1):\n",
    "                for j in range(i + 1, nr_cols + 1):\n",
    "                    xsni1_idx=index_state(nr_cols,n,s,i,nr_letters)\n",
    "                    xsni2_idx=index_state(nr_cols,n,s,j,nr_letters)\n",
    "                    Q[xsni2_idx][xsni1_idx] = 2 * p1\n",
    "\n",
    "    ## One letter pr. ith col terms\n",
    "    for s in range(1 , nr_rows + 1):\n",
    "        for i in range(1 , nr_cols + 1):\n",
    "            for n1 in range(1 , nr_letters[s]+ 1):\n",
    "                for n2 in range(n1 + 1 , nr_letters[s] + 1):\n",
    "                    xsni1_idx=index_state(nr_cols,n1,s,i,nr_letters)\n",
    "                    xsni2_idx=index_state(nr_cols,n2,s,i,nr_letters)\n",
    "                    Q[xsni1_idx][xsni2_idx] = 1 * p2\n",
    "    \n",
    "    ## Ordering term\n",
    "    for s in range(1 , nr_rows + 1):\n",
    "        for n1 in range(1 , nr_letters[s]+ 1):\n",
    "            for n2 in range(n1 + 1 , nr_letters[s] + 1):\n",
    "                for i1 in range(1 , nr_cols + 1):\n",
    "                    for i2 in range(i1 + 1 , nr_cols + 1):\n",
    "                        xsni1_idx=index_state(nr_cols,n1,s,i2,nr_letters)\n",
    "                        xsni2_idx=index_state(nr_cols,n2,s,i1,nr_letters)\n",
    "                        Q[xsni1_idx][xsni2_idx] = 1 * p3\n",
    "    \n",
    "    return Q,h,d\n",
    "\n",
    "def calculate_cost(Weights: np.ndarray, MSA: np.ndarray, state: np.ndarray, penalties: np.ndarray):\n",
    "    nr_rows,nr_cols = MSA.shape[0], MSA.shape[1]\n",
    "    nr_letters = [0] + [len(np.where(MSA[i] != \"_\")[0]) for i in range(nr_rows)]\n",
    "    vector_dim = np.sum(nr_letters) * nr_cols\n",
    "    p1,p2,p3   = penalties[0], penalties[1], penalties[2]\n",
    "    \n",
    "    weight_terms = 0\n",
    "    ## Weight terms\n",
    "    for s1 in range(1 , nr_rows + 1):\n",
    "        for s2 in range(s1 + 1, nr_rows + 1):\n",
    "            for n1 in range(1 , nr_letters[s1]+ 1):\n",
    "                for n2 in range(1 , nr_letters[s2] + 1):\n",
    "                    for i in range(1 , nr_cols + 1):\n",
    "                        xsni1_idx=index_state(nr_cols,n1,s1,i,nr_letters)\n",
    "                        xsni2_idx=index_state(nr_cols,n2,s2,i,nr_letters)\n",
    "                        row,col = index_weight(s1,n1,s2,n2,i,nr_cols,nr_letters)\n",
    "                        weight_terms += state[xsni1_idx]*state[xsni2_idx] * Weights[row][col]\n",
    "\n",
    "    p1_terms = 0\n",
    "    ## Remaing part of squared terms in one col pr. letter\n",
    "    for s in range(1 , nr_rows + 1):\n",
    "        for n in range(1 , nr_letters[s] + 1):\n",
    "            current_sum = 0\n",
    "            for i in range(1 , nr_cols + 1):\n",
    "                    xsni1_idx=index_state(nr_cols,n,s,i,nr_letters)\n",
    "                    current_sum += state[xsni1_idx]\n",
    "            p1_terms += (current_sum - 1) ** 2\n",
    "            \n",
    "    p2_terms = 0\n",
    "    ## One letter pr. ith col terms\n",
    "    for s in range(1 , nr_rows + 1):\n",
    "        for i in range(1 , nr_cols + 1):\n",
    "            for n1 in range(1 , nr_letters[s]+ 1):\n",
    "                for n2 in range(n1 + 1 , nr_letters[s] + 1):\n",
    "                    xsni1_idx=index_state(nr_cols,n1,s,i,nr_letters)\n",
    "                    xsni2_idx=index_state(nr_cols,n2,s,i,nr_letters)\n",
    "                    p2_terms += state[xsni1_idx]*state[xsni2_idx]\n",
    "    \n",
    "    p3_terms = 0\n",
    "    ## Ordering term\n",
    "    for s in range(1 , nr_rows + 1):\n",
    "        for n1 in range(1 , nr_letters[s]+ 1):\n",
    "            for n2 in range(n1 + 1 , nr_letters[s] + 1):\n",
    "                for i1 in range(1 , nr_cols + 1):\n",
    "                    for i2 in range(i1 + 1 , nr_cols + 1):\n",
    "                        xsni1_idx=index_state(nr_cols,n1,s,i2,nr_letters)\n",
    "                        xsni2_idx=index_state(nr_cols,n2,s,i1,nr_letters)\n",
    "                        p3_terms += state[xsni1_idx]*state[xsni2_idx]\n",
    "    \n",
    "\n",
    "    final_cost = weight_terms + p1 * p1_terms + p2 * p2_terms + p3 * p3_terms\n",
    "    return final_cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initial MSA ---\n",
      "[['A' 'G']\n",
      " ['G' '_']]\n",
      "w. corresponding state:\n",
      "[1. 0. 0. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "initial_strings = np.array([\"G\",\"AG\"])\n",
    "my_mat = initial_MSA_matrix(initial_strings)\n",
    "print(\"--- Initial MSA ---\")\n",
    "print(my_mat)\n",
    "state = matrix_2_bit_state(my_mat,my_mat)\n",
    "print(\"w. corresponding state:\")\n",
    "print(state)\n",
    "state = state.reshape((len(state),1))\n",
    "weights = encode_score_weights(my_mat)\n",
    "penalties = np.array([1,1,1])\n",
    "Q,h,d = encode_QUBO(weights,my_mat,penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Known optimal MSA ---\n",
      "[['A' 'G']\n",
      " ['_' 'G']]\n",
      "w. corresponding state:\n",
      "[1. 0. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "known_best_state = np.array([1,0,0,1,0,1],dtype=float)\n",
    "bit_state_2_matrix(known_best_state,my_mat)\n",
    "print(\"--- Known optimal MSA ---\")\n",
    "print(bit_state_2_matrix(known_best_state,my_mat))\n",
    "print(\"w. corresponding state:\")\n",
    "print(known_best_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using QUBO cost on all perms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = len(state)\n",
    "all_permutations = []\n",
    "for i in range(state_dim + 1):\n",
    "    current_perm = np.zeros(state_dim,dtype=int)\n",
    "    for ones in range(i):\n",
    "        current_perm[ones] = 1\n",
    "    letter_perms = list(set(permutations(list(current_perm))))\n",
    "    for perm in letter_perms:\n",
    "        all_permutations.append(np.array(list(perm),dtype=int).reshape((len(perm),1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Best state and corresponding cost according to QUBO model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, 1, 0, 1]), -1.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_state = None\n",
    "best_cost = np.inf\n",
    "history = []\n",
    "for perm in all_permutations:\n",
    "    cost = ((perm.T @ (Q @ perm) + h.T @ perm + d))[0][0]\n",
    "    history.append([perm.T[0],cost])\n",
    "    if cost < best_cost:\n",
    "        best_cost = cost\n",
    "        best_state = perm.T[0]\n",
    "states = np.array(history,dtype=object)[:,0]\n",
    "costs  = np.array(np.array(history,dtype=object)[:,1],dtype=float)\n",
    "print(\"-- Best state and corresponding cost according to QUBO model:\")\n",
    "best_state,best_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Cost of known best state according to QUBO model:\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-- Cost of known best state according to QUBO model:\")\n",
    "idx =np.array([i for i in range(len(states)) if np.all(states[i] == known_best_state)])\n",
    "print(costs[idx][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using hard-coded cost on all perms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Best state and corresponding cost according to hard-coded model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, 1, 0, 1]), -1.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalties = np.array([1,1,1])\n",
    "best_state = None\n",
    "best_cost = np.inf\n",
    "history = []\n",
    "for perm in all_permutations:\n",
    "    cost = calculate_cost(weights, my_mat, perm.T[0],penalties)\n",
    "    history.append([perm.T[0],cost])\n",
    "    if cost < best_cost:\n",
    "        best_cost = cost\n",
    "        best_state = perm.T[0]\n",
    "states = np.array(history,dtype=object)[:,0]\n",
    "costs  = np.array(np.array(history,dtype=object)[:,1],dtype=float)\n",
    "print(\"-- Best state and corresponding cost according to hard-coded model:\")\n",
    "best_state,best_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Cost of known best state according to hard-coded model:\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-- Cost of known best state according to hard-coded model:\")\n",
    "idx =np.array([i for i in range(len(states)) if np.all(states[i] == known_best_state)])\n",
    "print(costs[idx][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different penalty sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costs sum: 14400.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABbEAAANZCAYAAAAxgXP1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABCBklEQVR4nO3df7Cld30f9vcHyQUsTBeMRFRJaxFHNhae4pgd4poZTBGx1GIjT7E6cpOMmsHVtAbXTesfKzwxhla2MuNk4mbCpJrYrqaNjeXELjJkjEEEuTGYXw7+AUJGGCwERLIBORK0UiW+/eMezI24u3vu3vPjc57n9Zo5s7vnPvd9P8/z/Z5H8N6759YYIwAAAAAA0NETtj0AAAAAAACcihIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABo69xtD7BOz3jGM8all1667TEAAAAAADiN97///X82xjj/oI9NusS+9NJL8773vW/bYwAAAAAAcBpV9Sen+pi3EwEAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANraaoldVceq6p9X1Yer6s6q+k+q6ulV9daq+sji16ftO/6Gqrq7qu6qqiu3OTsAAAAAAOu37e/E/tkkvzHGeHaS5ya5M8nJJLePMS5Lcvviz6mqy5Ncm+Q5Sa5K8vqqOmcrUwMAAAAAsBFbK7Gr6qlJXpjk55JkjPHIGOOBJFcnuWVx2C1Jvmfx+6uTvGGM8fAY42NJ7k7y/E3ODAAAAADAZm3zO7H/cpI/TfILVfVvquqfVtV5SZ45xvh0kix+vWBx/EVJPrHv8+9dPAcAAAAAwESdu+Wv/a1JfnCM8e6q+tks3jrkFOqA58ZXHFR1fZLrk+T48eOrmBMAAABm4dKTbz7S53/8ppeuaBKA3eQ+uh7b/E7se5PcO8Z49+LP/zx7pfZ9VXVhkix+vX/f8Zfs+/yLk3zq8aFjjJvHGCfGGCfOP//8tQ0PAAAAAMD6ba3EHmP82ySfqKpvXDx1RZIPJbktyXWL565L8sbF729Lcm1VPbGqnpXksiTv2eDIAAAAAABs2DbfTiRJfjDJP6uq/yDJHyf529kr1m+tqlckuSfJNUkyxvhgVd2avaL70SSvHGM8tp2xAQAAAADYhK2W2GOMDyQ5ccCHrjjF8TcmuXGdMwEAAAAA0Mc23xMbAAAAAABOS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW1stsavq41X1B1X1gap63+K5p1fVW6vqI4tfn7bv+Buq6u6ququqrtze5AAAAAAAbEKH78T+T8cY3zLGOLH488kkt48xLkty++LPqarLk1yb5DlJrkry+qo6ZxsDAwAAAACwGR1K7Me7Oskti9/fkuR79j3/hjHGw2OMjyW5O8nzNz8eAAAAAACbsu0SeyT5zap6f1Vdv3jumWOMTyfJ4tcLFs9flOQT+z733sVzAAAAAABM1Llb/vovGGN8qqouSPLWqvrwaY6tA54bX3HQXhl+fZIcP358NVMCAAAAwIpcevLNR/r8j9/00rXmQTdb/U7sMcanFr/en+TXsvf2IPdV1YVJsvj1/sXh9ya5ZN+nX5zkUwdk3jzGODHGOHH++eevc3wAAAAAANZsayV2VZ1XVV/zpd8n+c4kf5jktiTXLQ67LskbF7+/Lcm1VfXEqnpWksuSvGezUwMAAAAAsEnbfDuRZyb5tar60hy/OMb4jap6b5Jbq+oVSe5Jck2SjDE+WFW3JvlQkkeTvHKM8dh2RgcAAAAAYBO2VmKPMf44yXMPeP4zSa44xefcmOTGNY8GAAAAAEATW31PbAAAAAAAOB0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG1tvcSuqnOq6t9U1ZsWf356Vb21qj6y+PVp+469oarurqq7qurK7U0NAAAAAMAmbL3ETvJDSe7c9+eTSW4fY1yW5PbFn1NVlye5NslzklyV5PVVdc6GZwUAAAAAYIO2WmJX1cVJXprkn+57+uoktyx+f0uS79n3/BvGGA+PMT6W5O4kz9/QqAAAAAAAbMG5W/76/zDJjyb5mn3PPXOM8ekkGWN8uqouWDx/UZLf2XfcvYvnAAAAAIAVufTkm8/6cz9+00tXOAns2VqJXVXfleT+Mcb7q+pFy3zKAc+NA3KvT3J9khw/fvwoIwIATRzlf0Qn/oc0QHfu8wDA6WzzO7FfkORlVfWfJ3lSkqdW1f+Z5L6qunDxXdgXJrl/cfy9SS7Z9/kXJ/nU40PHGDcnuTlJTpw48RUlNwAAAABA4i9Sd8XW3hN7jHHDGOPiMcal2fuBjW8fY/zNJLcluW5x2HVJ3rj4/W1Jrq2qJ1bVs5JcluQ9Gx4bAAAAAIAN2vZ7Yh/kpiS3VtUrktyT5JokGWN8sKpuTfKhJI8meeUY47HtjQkAAAAAwLq1KLHHGO9I8o7F7z+T5IpTHHdjkhs3NhgAAAAAAFu1tbcTAQAAAACAM1FiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgrUOV2FX1E1X1zaf5+HOq6ieOPhYAAAAAABz+O7F/Msl/fJqPf3OS15z1NAAAAAAAsM+q307kSUkeXXEmAAAAAAAzde6ZDqiqpyY5tu+pr62q4wcc+vQkfyPJJ1YzGgAAAAAAc3fGEjvJ30nypfe5Hkn+4eJxkEryo0eeCgAAAAAAslyJ/Y7Fr5W9MvvXkvz+444ZSR5K8jtjjHeubDoAAAAAAGbtjCX2GOOOJHckSVV9XZJ/MsZ497oHAwAAAACAZb4T+y+MMf72ugYBAAAAAIDHe8JhDq6q51fVf/O4566uqj+oqk9W1U+tdjwAAAAAAObsUCV2ktckedmX/lBVx5P8UpK/lOTPk/xYVflubQAAAAAAVuKwJfZzk/z2vj9fm70f+PgtY4zLk/xmkutXNBsAAAAAADN32BL7a5P8231/vjLJb40xPrn4821JLlvFYAAAAAAAcNgS+4Ekz0ySqnpikm9L8lv7Pj6SPHklkwEAAAAAMHuHLbE/kOT7q+p5Sf5ukiclecu+jz8ryX3LBFXVk6rqPVX1e1X1wap67eL5p1fVW6vqI4tfn7bvc26oqrur6q6quvKQswMAAAAAsGMOW2L/z0kuTPKeJK9O8rYxxvv2ffy7krx7yayHk7x4jPHcJN+S5Kqq+rYkJ5PcPsa4LMntiz+nqi7P3ntwPyfJVUleX1XnHHJ+AAAAAAB2yLmHOXiM8c6q+tbsvRf2nyd5w5c+VlVfm70f7PhrS2aNJA8t/vhVi8dIcnWSFy2evyXJO5L82OL5N4wxHk7ysaq6O8nzk7zrMOcAAADAtF168s1n/bkfv+mlK5wEAFiFQ5XYSTLG+KMkf3TA859J8ncOk7X4Tur3J/krSf7xGOPdVfXMMcanF5mfrqoLFodflOR39n36vYvnAAAAgIaO8hcKib9UgClwH2AVDl1iJ0lVPTXJS5L85cVTf5zkrWOMBw+TM8Z4LMm3VNWxJL9WVd98ui97UMQBs12f5PokOX78+GHGmRw3CZa16r1i78Humdvrdm7nC8vy2gDmxn2vD2sBnM6hS+yq+v4kfz/JU/LlYnkkeaiq/scxxs8dNnOM8UBVvSN773V9X1VduPgu7AuT3L847N4kl+z7tIuTfOqArJuT3JwkJ06c+IqSGwAAAJalWAPoxX15ng5VYlfVy7JXEP9xkp9I8oeLDz0nyQ8mubmq7h9j/PoSWecn+f8WBfaTs/ed3X8vyW1Jrkty0+LXNy4+5bYkv1hV/yDJf5Tksuz9gEkAAADYCcoXADi8w34n9o8muTPJXxtjPLTv+dur6hey957VP5bkjCV2kguT3LJ4X+wnJLl1jPGmqnpXklur6hVJ7klyTZKMMT5YVbcm+VCSR5O8cvF2JAAAAAAATNRhS+znJnnd4wrsJMkY48GquiXJ310maIzx+0n+6gHPfybJFaf4nBuT3HioiQEAAAAA2FlPOIvPOegHLH6J96AGAAAAAGBlDlti/16S66rqvMd/oKqekuS/XhwDAAAAAABHdti3E/mZJL+a5Her6n/N3vtTJ1/+wY5/Jcl/sbrxAAAAAACYs0OV2GOM/6uqXpXk7yX5R/ny24dUks8nedUY442rHREAAAAAgLk67HdiZ4zx+qr6xSR/PcmzsldgfzTJW8cYf77i+QAAAAAAmLFDl9hJMsZ4IMmvrHYUAAAAAAD4953xBztW1TlVdVNV/bdnOO6/q6qfqqpa3XgAAAAAAMzZGUvsJH8zyY8kee8ZjntPkh9L8n1HHQoAAAAAAJLlSuz/MsnbxhjvP91Bi4+/JUpsAAAAAABWZJkS+3lJ3rZk3r9KcuLsxwEAAAAAgC9bpsR+epL7l8z708XxAAAAAABwZMuU2A8mecaSeV+b5KGzHwcAAAAAAL5smRL7g0m+c8m8v744HgAAAAAAjmyZEvtXk7ykqq4+3UFV9bLsldj/YhWDAQAAAADAMiX2/5bk7iS3VtWNVXXp/g9W1aVV9b8kuTXJHy2OBwAAAACAIzv3TAeMMf6fqnppkjcluSHJyap6MMm/S/I1SZ6apJLcleS7xhj/7xrnBQAAAABgRpb5TuyMMe5O8i1JfijJv07yaJK/lOSxJP/34vlvHWN8dD1jAgAAAAAwR2f8TuwvWXyH9T9aPAAAAAAAYO2W+k5sAAAAAADYBiU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0tbUSu6ouqap/VVV3VtUHq+qHFs8/vareWlUfWfz6tH2fc0NV3V1Vd1XVlduaHQAAAACAzdjmd2I/muR/GmN8U5JvS/LKqro8yckkt48xLkty++LPWXzs2iTPSXJVktdX1TlbmRwAAAAAgI3YWok9xvj0GON3F79/MMmdSS5KcnWSWxaH3ZLkexa/vzrJG8YYD48xPpbk7iTP3+jQAAAAAABs1LnbHiBJqurSJH81ybuTPHOM8elkr+iuqgsWh12U5Hf2fdq9i+cAACbl0pNvPtLnf/yml64sb5VZB+XNjesHMG3u8wDrsfUSu6qekuRfJPkfxhj/rqpOeegBz40D8q5Pcn2SHD9+fFVjktX+x7jT/zmXRydzW9vu59t9PgCAuf3vlbmdb2fd18L/D4dp2WqJXVVflb0C+5+NMX518fR9VXXh4ruwL0xy/+L5e5Ncsu/TL07yqcdnjjFuTnJzkpw4ceIrSm4AAGAzVvmvAOame/mizIH18zoD+LKtvSd27X3L9c8luXOM8Q/2fei2JNctfn9dkjfue/7aqnpiVT0ryWVJ3rOpeQEAAAAA2Lxtfif2C5L8rSR/UFUfWDz36iQ3Jbm1ql6R5J4k1yTJGOODVXVrkg8leTTJK8cYj218agAAAAAANmZrJfYY41/n4Pe5TpIrTvE5Nya5cW1DAQAAAADQytbeTgQAAAAAAM5EiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbWyuxq+rnq+r+qvrDfc89vareWlUfWfz6tH0fu6Gq7q6qu6rqyu1MDQAAAADAJm3zO7H/9yRXPe65k0luH2NcluT2xZ9TVZcnuTbJcxaf8/qqOmdzowIAAAAAsA1bK7HHGL+V5LOPe/rqJLcsfn9Lku/Z9/wbxhgPjzE+luTuJM/fxJwAAAAAAGzPudse4HGeOcb4dJKMMT5dVRcsnr8oye/sO+7exXMA8BcuPfnmI33+x2966YomYW5rMbfzBQAA2KRuJfap1AHPjQMPrLo+yfVJcvz48XXOBOyoo5RNu1Y0rbpYU9QdzSr3nrVgKuzlo3H9zp7/RgJz4z4F7LJuJfZ9VXXh4ruwL0xy/+L5e5Ncsu+4i5N86qCAMcbNSW5OkhMnThxYdAO7pfP/2Oo8GwBMif/mAgDM1zZ/sONBbkty3eL31yV5477nr62qJ1bVs5JcluQ9W5gPAAAAAIAN2tp3YlfVLyV5UZJnVNW9SV6T5KYkt1bVK5Lck+SaJBljfLCqbk3yoSSPJnnlGOOxrQwOAAAAAMDGbK3EHmN83yk+dMUpjr8xyY3rmwgAAAAAgG66vZ0IAAAAAAD8BSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbe1ciV1VV1XVXVV1d1Wd3PY8AAAAAACsz06V2FV1TpJ/nOQ/S3J5ku+rqsu3OxUAAAAAAOuyUyV2kucnuXuM8cdjjEeSvCHJ1VueCQAAAACANTl32wMc0kVJPrHvz/cm+WtbmgUAgIm79OSbj/T5H7/ppSuaBAAA5qvGGNueYWlVdU2SK8cY37/4899K8vwxxg/uO+b6JNcnyfHjx5/3J3/yJ1uZFQCAzbvz2d90pM//pg/fuaJJAACAw6iq948xThz0sV17O5F7k1yy788XJ/nU/gPGGDePMU6MMU6cf/75Gx0OAAAAAIDV2rW3E3lvksuq6llJPpnk2iT/1XZHAgCgC99JDQAA07NTJfYY49GqelWStyQ5J8nPjzE+uOWxAAAAAABYk50qsZNkjPEvk/zLbc8BAAAAAMD67dp7YgMAAAAAMCNKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbSmxAQAAAABoS4kNAAAAAEBbSmwAAAAAANpSYgMAAAAA0JYSGwAAAACAtpTYAAAAAAC0pcQGAAAAAKAtJTYAAAAAAG0psQEAAAAAaEuJDQAAAABAW0psAAAAAADaUmIDAAAAANCWEhsAAAAAgLaU2AAAAAAAtKXEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxAYAAAAAoC0lNgAAAAAAbdUYY9szrE1V/WmSP9n2HI09I8mfNc3rPJu8aed1nk3etPM6zyZv2nmdZ5Mnb1tZ8uRtK0uevG1lyZO3rSx57Pd1Y4zzD/rApEtsTq+q3jfGONExr/Ns8qad13k2edPO6zybvGnndZ5NnrxtZcmTt60sefK2lSVP3ray5LEsbycCAAAAAEBbSmwAAAAAANpSYs/bzY3zOs8mb9p5nWeTN+28zrPJm3Ze59nkydtWljx528qSJ29bWfLkbStLHkvxntgAAAAAALTlO7EBAAAAAGhLiQ0AAAAAQFtKbAAAAAAA2lJiAwAAAADQlhIbAAAAAIC2lNgAAAAAALSlxJ6pqvpoVb23W5Y8edvKkidvW1ny5G0rS568beZ1nk3etPM6zyZv2nmdZ5M37bzOs8njUMYYHjN7JLkiyaNJHkvy3C5Z8uRNZTZ5087rPJu8aed1nk2evKnMJm/aeZ1nkzftvM6zyZt2XufZ5B09b26PWlxEZqSqfinJsST/YZLfHWO8qkOWPHlTmU3etPM6zyZv2nmdZ5MnbyqzyZt2XufZ5E07r/Ns8qad13k2eUfPm51tt+gem30keVqSLyS5Jsn1ST6b5InbzpInbyqzyZt2XufZ5E07r/Ns8uRNZTZ5087rPJu8aed1nk3etPM6zybv6HlzfGx9AI8NL3jy3yf50yRfleSpST6f5G9sO0uevKnMJm/aeZ1nkzftvM6zyZM3ldnkTTuv82zypp3XeTZ5087rPJu8o+fN8bH1ATw2vODJ7yX52X1//j+SvGPbWfLkTWU2edPO6zybvGnndZ5NnrypzCZv2nmdZ5M37bzOs8mbdl7n2eQdPW+Oj60P4LHBxU5O5HFvHp+9N5V/LMnXbytLnrypzCZv2nmdZ5M37bzOs8mTN5XZ5E07r/Ns8qad13k2edPO6zybvKPnzfWx9QE8NrjYyT9J8v4Dnv9Ykp/aVpY8eVOZTd608zrPJm/aeZ1nkydvKrPJm3Ze59nkTTuv82zypp3XeTZ5R8+b62PrA3hsaKGTJyd5IMmrDvjYTyb5VJInbDpLnjx7T94u5HWeTd608zrPJk+evSxvF/I6zyZv2nmdZ5M37bzOs8k7et6cH1sfwGNDC508M8l1Sb7mgI9dsPjYsU1nyZNn78nbhbzOs8mbdl7n2eTJs5fl7UJe59nkTTuv82zypp3XeTZ5R8+b86MWFw0AAAAAANp5wrYHYPOq6tyqOqdblrzpm9PeW7Xu59s9b5U6z7YO3de2e94qdZ5tHbqfb/f5Vq3z+c7pPpD0n2/VOp9v59nWwfn2yNoFczvfzqwFU6LEnoGquqCqXldV762qB5M8nOSRqnpw8dxrq+r8TWfJO3rekl/zeVX189vIm9PeW/JrbuXazTFvya+51Hp0nm0ded3Xtnvekl/T3jv42Nbn232+Vedt+nyndJ9a8mu2XYvDzrfqvDntvVXPt+o859vn/7ss+TUnce3WMd+c8qyFvCnzdiITV1XPTfK2JCPJrye5M8nnklSSY0meneS7F39+yRjj9zeRJe/oecuqqpcnuXWMsarvIlgqb057b1nbuHZzzFvWMuvRebZ15HVf2+55y7L3Djyu9fl2n2/Veds436ncp5bVeS0OM9+q8+a091Y936rznG+f/++yrClcu3XMN6c8ayFv6pTYE1dVdyR5KMk1Y4wvnOKYr07yK0nOG2O8aBNZ8laS98LTfXyfFyV5zRL/42PVeXPae22v3UzzVrYenWdbU173te2eZ++dfV738+0+X9vz7TzbmvK6n6+912C2Nc3nfI+W1/n/u8zm2q1pvtnkWYtp55Fs/SdLeqz3keQLSV68xHEvTvL5TWXJW0neF5M8tvj1TI/HtpA3p73X9trNNG9l69F5NnuvZZ6912fvzW2+tufbebYdWdvu87U9386zzW0t5na+rt3kz7dtnrWYdp7HyLlh6v4syTcmefsZjnt2ks9sMEve0fM+m+Q3kvz0GY77ziQ/s4W8Oe29ztdujnmrXI/Os60jr/vads+z984+r/v5dp+v8/l2nm0ded3P197rMVsyr7VI5nW+rt3BpnK+nfOsxbTz2HaL7rHeR5JXJ/l8kh9P8g1ZvIXM4mOV5LLFMQ8luWFTWfJWkvemJL+9xHEvz3J/S7jqvDntvbbXbqZ5K1uPzrPZey3z7L0+e29u87U9386z7cjadp+v7fl2nm1uazG383XtJn++bfOsxbTzPIYSew6PJDckeSB7/4zhkez9bdBnFr9/bPGxk5vOknfktfiBJO9a4rjnJfmFTefNae91v3Zzy1vDa6PzbPZeozx7r8/em9t8nc+382y7sLbd5+t8vp1nm9tazPR8XbuJnu8O5FmLieZ5DD/YcS6q6olJXpC9f1rytMXTn0vy4STvHGM8vI2sHcr79uz9k5t283W3hr03m7XYkb08i/XoPNs67Mjea/vfjVVa9bXrrvv5dp9v1eb02ui+tt3nW7U57b3uOq/FOqxyfWe6V2Zzvp1ZC6ZKiQ0AAAAAQFt+sONMVNVTknxHvvw3cSN7/4zkw0nuGGM8tI2sXchb4us9KckFY4x7tjHf3M6382zd85b4eoe6fqvO63z9Os+2C3lLfL3J7JV15J3ha7W9J5/NfKvOc77T3cvd8+w9e89abCZvia/Xdn23vbarnm/Vec7XfU8eX2Fb72PisZlH9t68/3XZe+P+Ly5+/USSe5M8uO+512bfm/6vO2sX8g5xjZd9U3/nu+b5prIW3dd2TuvRebZdyJvTXtnW9dvWtVv1fM631/l23svd8+w9e89a9Fnb7uvrvuJ8t3W+nV8X8jxOe622PYDHmhd470b3UJIfSXLJAR+/OMkPL26OP7mprF3IO8Q1XvY/Ts53zfNNZS26r+2c1qPzbLuQN6e9sq3rt61rt+r5nG+v8+28l7vn2Xv2nrXos7bd19d9xflu63w7vy7keZzu4T2xJ66qPpnktWOMm89w3PVJXjPGuGgTWTuS9/bTfXyf85NcPsY4Z8PzzeZ8O8+2I3mrvn6zWY/Os+1I3mz2yqrzduDaze2+Mrfz7byXu+fZewcfZ++tP6/tWqwpr+167MDatr12izzne/Bx7nszz8N7Ys/BsSQfXeK4jy6O3VTWLuS9MMldST50huOetERW4nxPZZn5Os+2C3mrvn5zWo9VZs0xb057ZdV53a/d3O4rczvfVeZ1v3bd12Ju57vKvO7Xbk5rsY68zuvRfW07X7vE+Z6K+548RoNvB/dY3yPJ7UnekuS80xxzXpLfTPK2TWXtSN4HkvzyEsd9b5b7Z0LO9+z3XtvZdiRv1ddvNuvRebYdyZvNXlnD3ut+7eZ2X5nb+Xbey93z7D17z1psJq/teuzA2ra9ds73aOe7A+cq7wh5HsN3Ys/Aq5K8Lck9VfWW7P1k2wey95Nuj2XvJ99emeThJFdsMGsX8t6d5KoljhvZ+2EMm55vTufbebZdyFv19ZvTenSebRfy5rRXVp3X/drN7b4yt/PtvJe759l79p612Exe5/Xovradr13ifN335HEq227RPdb/yN6N74YkdyS5L8kji8d9i+dOJjm26azueUm+PsnLljjuyUm+zvmub77Os+1C3qqv39zWo/Ns3fPmtldWmdf92q16Pufb63w77+XuefaevWctvDa6r23na+d83ffkeZzu4Qc7AgAAAADQ1hO2PQCbV1XnVtVKfurpKrPmmLdqczrfzrPtgu7Xr/Ne7jybvH7svT553c3p+s3pXOnFXuml+73Afpkua3v2XDu2SYk9A1V1QVW9rqreW1UPZu+9lB6pqgcXz722qs7fdNYc85b8ms+rqp/fxnydz7fzbLuQ1/36dd7LnWeTN+293P3adc9b8mtO5r7c+frN6Vzl9cqzV3rldb8XbHq/TGltu+e5F5x9lmu3e3lT5u1EJq6qnpu9HxIwkvx6kjuTfC57bxp/LHs/JOC7F39+yRjj9zeRNce8ZVXVy5PcOsY47d9uzul8O8+2C3ndr1/nvdx5NnnT3svdr133vGVN5b7c+frN6Vzl9cqzV3rldb8XbGO/TGVtu+e5F5x9lmu3m3lTpsSeuKq6I8lDSa4ZY3zhFMd8dZJfSXLeGONFm8iaad4LT/fxfV6U5DVL/AdlNufbebYdyet+/dru5c6zyZv2Xt6Ba9c9b2735bbXb07nKq9Xnr3SLq/7vWCV/w3vvhZzy5vNvcC1m3YeydZ/sqTHeh9JvpDkxUsc9+Ikn99U1kzzvpjkscWvZ3o85nx3Y7Ydyet+/dru5c6zyZv2Xt6Ba9c9b2735bbXb07nKq9Xnr3SLq/7vWCV/w3vvhZzy5vNvcC1m3aex8i5Yer+LMk3Jnn7GY57dpLPbDBrjnmfTfIbSX76DMd9Z5KfWSJvTufbebZdyOt+/Trv5c6zyTt6Xue93P3adc+b23258/Wb07nK65Vnr/TK634vWGVe97WYW96c7gWu3bTz2HaL7rHeR5JXJ/l8kh9P8g1ZvIXM4mOV5LLFMQ8luWFTWTPNe1OS317iuJdnub/Vm835dp5tR/K6X7+2e7nzbPKmvZd34Np1z5vbfbnt9ZvTucrrlWevtMvrfi9Y5X/Du6/F3PJmcy9w7aad5zGU2HN4JLkhyQPZ+2cMj2Tvb4M+s/j9Y4uPndx01tzykvxAknctcdzzkvyC892p2Vrndb9+O7CX284mb9p7ufO165636rXtvld24PrN6Vzl9cqzV5rkrXo9Oud1X4u55a16r3Q+X9du2nkeww92nIuqemKSF2Tvn4I8bfH055J8OMk7xxgPHzLr27P3T0aOlLXq2XYhb9XmdL6r3ntz03ltk973ljXN1vJcdyiv7b1glfPtyFrMZm1XbU7Xr/t9lOnq/r9/5qb7vcC9Zbqs7dlz7ehCiQ0AAAAAQFt+sONMVNVTknxHvvw3ZyN7/+zjw0nuGGM8tMKv9aQkF4wx7tnGbPJ65S3x9Q61X1aZ1f3azS1via+31fVd5Wyrzuu+tt33Sue87mvRfW27n+/crt8qZ1t1nrXtNd8q8+Z0rovjZ3W+nfO6r0X3+brn7fL1c+2mnTdp23ofE4/NPLL3Zvuvy94b7X9x8esnktyb5MF9z702+96k/4hfc9k3uV/pbPJ65a16v9h7083rvr6b3sf28u6uxyrzuq9F97Xtfr5zu35dX2fWtt98q8yb07nO8Xw753Vfi+7zdc+bwvVz7aadN+XH1gfwWPMC7734H0ryI0kuOeDjFyf54cUN4ydX9DWXvYGtdDZ5vfJWvV/svenmdV/fTe9je3l312OVed3Xovvadj/fuV2/Vc7W/VytbZ/1ndO5zvF8O+d1X4vu83XPm8L1c+2mnTflh/fEnriq+mSS144xbj7Dcdcnec0Y46LTHPP2Jb/s+UkuH2Ocs6nZ5LXMW9l+sfcmn9d2fdcwW9tz3ZG87uuxyvte97Xovrbdz3c216/z62yRZ217zdf5Ptr2XBd5czvftnk7sBbd5+ue1/b6uXZHnq91Ht4Tew6OJfnoEsd9dHHs6bwwyV1JPnSG4560xNdLVjubvH55q9wv9t608zqv76pn63yuu5DXfT1WmXcsvddi1XleG0fL63z9Or/OEmt7KlO4Lx/LfM41md/5ds47lt5rcSy95+uedyx9r59rd7Cp7D1Gg28H91jfI8ntSd6S5LzTHHNekt9M8rYzZH0gyS8v8TW/N8v9U5KVzSavZd7K9ou9N/m8tuu7htnanuuO5HVfj1Xe97qvRfe17X6+s7l+nV9n1rblfCvLm9O5zvR82+btwFp0n697Xtvr59q1O9+V5nkM34k9A69K8rYk91TVW7L3014fyN5Pfz2WvZ8Ge2WSh5NccYasdye5aomvObL3hv2bnE1ev7xV7hd7b9p5ndd31bN1PtddyOu+HqvM674W3de2+/nO6fp1fp0l1rbbfJ3vo53PNZnf+XbO674W3efrntf5+rl2R5uvex7bbtE91v/I3s3ghiR3JLkvySOLx32L504mObZEztcnedkSxz05yddtcjZ5/fJWuV/svWnndV7fVc/W+Vx3Ia/7eqwhr+1adF/b7uc7p+vX/XVmbXvNt4a82Zzr3M53B/LarkX3+brndb5+rl2v813H9Zv7ww92BAAAAACgrSdsewA2r6rOraqV/NTTVWatw6rnk9cnr/Ns68jrbk7n232vdF8L801X973cPW/VOs/XebZd0H0vW9+z59odzZyuX/fX7ZzWgl7svWlTYs9AVV1QVa+rqvdW1YPZe3+hR6rqwcVzr62q8zeddYj5n1dVP7+N+eT1yes82zrylvyaS782Vp03p/Ptvle6r4X5jjbfJrMOm9d9L3fPW/JrTmIvd55tF/K67+VdX98pre2q5+uet+vXz33gaKa0lzed13m2w+bZe/Pi7UQmrqqem703zh9Jfj3JnUk+l703jT+WvTfO/+7Fn18yxvj9TWQd8hxenuTWMcZp/zZt1fPJ65PXebZ15C1r2dfGqvPmdL7d90r3tTDf0ebbdNZh8rrv5e55y5rCXu482y7kdd/LU1jfqaztqufrnjeF6+c+cDRT2cvbyOs822Hy7L35UWJPXFXdkeShJNeMMb5wimO+OsmvJDlvjPGiTWQtjn3hMueQ5EVJXrPEDWzV88lrktd5tjXlrfq10f211vZ8d2CvdF8L853lfJ1fF4u87nu5e1739eh8H+3+2ui+tt3z3Ef//WO8Nk6d1/b67cC5ds/rvvfa5nWebU15s9p7JFv/yZIe630k+UKSFy9x3IuTfH5TWYvjvpjkscWvZ3o8tslzldcrr/Nsa8pb9Wuj+2ut7fnuwF7pvhbmO/u91/Z1sSN7uXte9/XofB/t/trovrbd89xHG1y7Hclre/124Fy753Xfe23zOs+2I6+N1ufrMXJumLo/S/KNSd5+huOeneQzG8xKks8m+Y0kP32G474zyc8skbfq+eT1yes82zryVv3a6P5a63y+3fdK97Uw38GWma/z6yLpv5e753Vfj8730e6vje5r2z3PffQreW0crPP1636u3fO6773OeZ1nW0fe3PYe227RPdb7SPLqJJ9P8uNJviGLt5BZfKySXLY45qEkN2wqa/E5b0ry20sc9/Is97dcq55PXpO8zrPtyGuj+2ut7fnuwF7pvhbmO/u91/Z1sSN7uXte9/XofB/t/trovrbd89xHG1y7Hclre/124Fy753Xfe23zOs+2prxZ7T2PocSewyPJDUkeyN4/Y3gke38b9JnF7x9bfOzkFrJ+IMm7ljjueUl+YdPzyeuV13m27q+NVefN7Xw775Xua2G+s5+v++ui+17untd9Pdaw/zrP1jqv+17uvL5zW9vu5zun69f9XLvndd97nfM6z7aOvLntPY/hBzvORVU9MckLsvdPLZ62ePpzST6c5J1jjIe3kbUOi/m+PXv/ZOTI8636fOWdfd6aZmu7V7qb0/l23yurnm/VzDdda3ptzCZv1TrPN6f/ZqxD5/99to68OXHtjqbzfW/Vuv83bU5rQS/23nwosQEAAAAAaMsPdpyJqnpKku/Il/9mamTvn1V8OMkdY4yHtpG1jrwlvt6TklwwxrhnG/PJ67P3lvh69oq8Zb/WVvfKqueTd7S8zntPXq+8Od0Lut/j5U077wxfa1L/e2+Jrzep++gu53WerUNe99faLr92t7223fN2eW0nb1vvY+KxmUf23sz+ddl7I/svLn79RJJ7kzy477nXZt+b4K87ax15h7gmy74Jf+vznVOevSJvm3md98qq55O3e+s7lWs3t7w53Qu63+PlTTuv8+t2G+d6mPOVt/68zrNtM6/7a20Kr92p7JXue29b5zvlx9YH8FjzAu+9uB5K8iNJLjng4xcn+eHFC/InN5W1jrxDXJNlb2Ctz3dOefaKvO73lm3tlVXPJ2/31ncq125ueXO6F3S/x8ubdt6q9vFUzvUw5ytv/XmdZ9tmXvfX2hReu1PZK9333rbOd8oP74k9cVX1ySSvHWPcfIbjrk/ymjHGRZvIWlPe20/38X3OT3L5GOOcDc8n7yzz7BV528rbgb2y6vnkHS2v896T1ytvNveCzvd4edPO24HX7WzuA3PL6zzbjuR1f621fe3uwNp2z2u7tuw5d9sDsHbHknx0ieM+ujh2U1nryHthkruSfOgMxz1piayk//nOKW+VWYm9Im/5vO57ZdXzyTta3rH03XvyeuUdy3zuBcfS9x4vb9p53V+3q87rfB+YW17n2XYh71h6v9ZWnWfv9ck7lr5rS+LtRKb+SHJ7krckOe80x5yX5DeTvG1TWWvK+0CSX17iuO/Ncv+UpPv5zibPXpG3xb3Xfa+sej55TdZ3B85VXpO90v1813Cu8uRN5b/hs7kPzC2v82w7ktf9tdb2tbsDa9s9r+3aeuw9fCf29L0qyduS3FNVb8neT1N9IHs/XfVY9n7a6pVJHk5yxQaz1pH37iRXLXHcyN4b9m96Pnl99p69Im/ZvO57ZdXzyTtaXue9J69X3pzuBZ3v8fKmndf9dTun+8Dc8jrPtgt53V9rnV+73de2e17ntSXxndhzeGTvxXZDkjuS3JfkkcXjvsVzJ5Mc23TWGmb7+iQvW+K4Jyf5ul0/37nl2SvytpHXfa+sej55fda3+7nK67NXduF8V3mu8uQtm9f9dbvqvFWfr7yzz+s82y7kLY5t+1pbdZ691yev89p67D38YEcAAAAAANrydiITV1XHj/L5Y4x71pElT95h8jrPJm/aeZ1nkzftvM6zyZN3mLzOs8mbdl7n2eRNO6/zbPKmndd5NnlHzyO+E3vqquqL2Xt/neTU77Fz0CaoJGOMcc46sjaQdxjbmE/eIfLsFXnbytuxvbLq+eQdLa/z3pPXK2/S94LO93h5087bsdftpO8Dc8vrPNsO5nV/rbV67e7Y2nbPa7W27PGd2NP3rKZZ8uRtK0uevG1lyZO3rSx58raZ13k2edPO6zybvGnndZ5N3rTzOs8mjyPzndgAAAAAALT1hG0PAAAAAAAAp6LEBgAAAACgLSU2AAAAAABtKbEBAAAAAGhLiQ0AAAAAQFv/P+s786hkn/9vAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1800x1008 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1,p2,p3 = 100,100,100\n",
    "Q,h,d = encode_QUBO(weights,my_mat,np.array([p1,p2,p3]))\n",
    "history = []\n",
    "for perm in all_permutations:\n",
    "    cost = calculate_cost(weights, my_mat, perm.T[0], (p1,p2,p3))\n",
    "    #cost = ((perm.T @ (Q @ perm) + h.T @ perm + d))[0][0]\n",
    "    history.append([perm.T[0],cost])\n",
    "states = np.array(history,dtype=object)[:,0]\n",
    "costs  = np.array(np.array(history,dtype=object)[:,1],dtype=float)\n",
    "print(\"costs sum:\",np.sum(costs))\n",
    "\n",
    "xs = np.arange(0,len(states))\n",
    "ys = costs\n",
    "\n",
    "x_labels = []\n",
    "for state in states:\n",
    "    current_state_str = \"|\"\n",
    "    for nr in state.astype(np.int64):\n",
    "        current_state_str += str(nr)\n",
    "    current_state_str += \">\"\n",
    "    x_labels.append(current_state_str)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(25,14))\n",
    "ax.set_xticks(xs)\n",
    "ax.set_xticklabels(x_labels, rotation = 90,size=15)\n",
    "ax.bar(xs,ys,color=[\"tab:blue\" if ys[i] > 0 else \"tab:red\" for i in range(len(xs))])\n",
    "ax.set_ylabel(\"Cost\",size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 11, 1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the relationship betweem p1,p2,p3 yielding lowest standard deviation without best state all_permutations[29]\n",
    "norm_stds = []\n",
    "penalties = []\n",
    "for p1 in range(1 , 20):\n",
    "    for p2 in range(1 , 20):\n",
    "        for p3 in range(1 , 2):\n",
    "            Q,h,d = encode_QUBO(weights,my_mat,np.array([p1,p2,p3]))\n",
    "            my_costs = []\n",
    "            for perm in all_permutations:\n",
    "                my_costs.append(((perm.T @ (Q @ perm) + h.T @ perm + d))[0][0])\n",
    "            norm_stds.append(np.std((np.array(my_costs)/np.sum(np.array(my_costs)))))\n",
    "            penalties.append([p1,p2,p3])\n",
    "min_idx = np.argwhere(norm_stds==np.min(norm_stds))[0][0]\n",
    "penalties[min_idx]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de9184fb1100b1b99a61021f59422ac28d78a243336732ae833608768c206ac0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
